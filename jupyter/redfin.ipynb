{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preparation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>Libraries</b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# bs4\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "# selenium\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver import ChromeOptions\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.support.ui import Select\n",
    "from selenium.webdriver.chrome.webdriver import WebDriver\n",
    "from selenium.webdriver.remote.webelement import WebElement\n",
    "\n",
    "# data structures\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# database\n",
    "import sqlite3\n",
    "import csv\n",
    "\n",
    "# others\n",
    "import sys, os, re, glob, datetime, time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>UDF</b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# login to redfin\n",
    "def login_to_redfin(browser: WebDriver, email: str, password: str) -> None:\n",
    "    time.sleep(5)\n",
    "    # begin logging\n",
    "    browser.find_element(By.XPATH, \"//span[text()='Join / Sign in']/..\").click()\n",
    "    \n",
    "    # email\n",
    "    time.sleep(1)\n",
    "    browser.find_element(By.XPATH, \"//input[@name='emailInput']\").send_keys(email)\n",
    "    browser.find_element(By.XPATH, \"//span[text()='Continue with Email']/..\").click()\n",
    "\n",
    "    # password\n",
    "    time.sleep(1)\n",
    "    browser.find_element(By.XPATH, \"//input[@name='passwordInput']\").send_keys(password)\n",
    "    browser.find_element(By.XPATH, \"//span[text()='Continue with Email']/..\").click()\n",
    "\n",
    "    return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get links to cities' pages\n",
    "def get_cities_links(browser: WebDriver) -> tuple[list, list]:\n",
    "    time.sleep(1)\n",
    "    # get list of cities\n",
    "    cities = browser.find_elements(By.XPATH, f\"//span[text()='Search for homes by city']/following-sibling::ul/child::li\")\n",
    "    \n",
    "    # show more button to get all the names of cities\n",
    "    try:\n",
    "        browser.find_element(By.XPATH, \"//span[text()='Search for homes by city']/parent::*//span[text()='Show more']\").click()\n",
    "    except:\n",
    "        pass\n",
    "\n",
    "    # get link for each city\n",
    "    def _adjust_format(web_ele: WebElement) -> str:\n",
    "        text = web_ele.text.strip().lower()\\\n",
    "            .replace(' real estate', '')\\\n",
    "                .replace(' ', '_')\\\n",
    "                    .replace('.', '')\n",
    "        return text\n",
    "    names = list(map(_adjust_format, cities))\n",
    "    links = [city.find_element(By.XPATH, \".//child::a\").get_attribute('href') for city in cities]\n",
    "\n",
    "    return names, links"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>UDC</b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CSV_Transformer():\n",
    "    def __init__(self, intermediate_dir: str, target_dir: str, fixed_name: str) -> None:\n",
    "        self.intermediate_dir = intermediate_dir\n",
    "        self.target_dir = target_dir\n",
    "        self.fixed_name = fixed_name\n",
    "\n",
    "    # clear intermediate directory\n",
    "    def _cldir(self):\n",
    "        files_names = os.listdir(self.intermediate_dir)\n",
    "        for name in files_names:\n",
    "            os.remove(f'{self.intermediate_dir}/{name}')\n",
    "\n",
    "    # create a new file\n",
    "    def _create_new_file(self):\n",
    "        try:\n",
    "            file_name = os.listdir(self.intermediate_dir)[0]\n",
    "            # get selected rows except the 2nd row\n",
    "            with open(f'{self.intermediate_dir}/{file_name}', 'r+') as f:\n",
    "                reader = csv.reader(f, delimiter=',')\n",
    "                rows = [row for i, row in enumerate(reader) if i != 1]\n",
    "\n",
    "            # add new csv file\n",
    "            with open(f'{self.target_dir}/{self.fixed_name}.csv', 'w+') as f:\n",
    "                writer = csv.writer(f)\n",
    "                writer.writerows(rows)\n",
    "\n",
    "        except Exception as e:\n",
    "            print(e)\n",
    "\n",
    "    # update an existing file\n",
    "    def _update_file(self):\n",
    "        # reading the existing file\n",
    "        with open(f'{self.target_dir}/{self.fixed_name}.csv', 'r+') as f:\n",
    "            reader = csv.reader(f, delimiter=',')\n",
    "            existing_rows = [row for row in reader]\n",
    "\n",
    "        # reading the downloaded file\n",
    "        try:\n",
    "            file_name = os.listdir(self.intermediate_dir)[0]\n",
    "            with open(f'{self.intermediate_dir}/{file_name}', 'r+') as f:\n",
    "                reader = csv.reader(f, delimiter=',')\n",
    "                # excep the 2nd row\n",
    "                new_rows = [row for i, row in enumerate(reader) if (row not in existing_rows) and (i != 1)]\n",
    "\n",
    "            # append new rows to the existing file if available\n",
    "            if new_rows:\n",
    "                with open(f'{self.target_dir}/{self.fixed_name}.csv', 'a+') as f:\n",
    "                    writer = csv.writer(f)\n",
    "                    writer.writerows(new_rows)\n",
    "        except Exception as e:\n",
    "            print(e)\n",
    "\n",
    "    # transform content inside\n",
    "    def transform(self):\n",
    "        # available \n",
    "        if not os.path.exists(f'{self.target_dir}/{self.fixed_name}.csv'):\n",
    "            self._create_new_file()\n",
    "            print(f'Created {self.fixed_name}.csv')\n",
    "        \n",
    "        # unavailable\n",
    "        else:\n",
    "            self._update_file()\n",
    "            print(f'Updated {self.fixed_name}.csv')\n",
    "\n",
    "        # clear files for new iteration\n",
    "        self._cldir()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Selenium"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>Preparation</b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# header: user-agent\n",
    "user_agent = 'Mozilla/5.0 (X11; Linux x86_64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/60.0.3112.50 Safari/537.36'\n",
    "# options\n",
    "chrome_options = ChromeOptions()\n",
    "chrome_options.add_argument(f'user-agent={user_agent}')\n",
    "# browser\n",
    "url_redfin = 'https://www.redfin.com/'\n",
    "browser = webdriver.Chrome(options=chrome_options)\n",
    "browser.get(url_redfin)\n",
    "time.sleep(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# redfin logging\n",
    "email = 'john.lukestein@gmail.com'\n",
    "password = 'redfin.0504'\n",
    "login_to_redfin(browser, email, password)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>Store Data as CSV</b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# prepare directories\n",
    "cwd = os.getcwd()\n",
    "# intermediate\n",
    "os.chdir('../resource/temp')\n",
    "intermediate_dir=os.getcwd()\n",
    "\n",
    "# target \n",
    "os.chdir('../data/csv/api')\n",
    "target_dir = os.getcwd()\n",
    "os.chdir(cwd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# options for browser\n",
    "user_agent = r'Mozilla/5.0 (X11; Linux x86_64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/60.0.3112.50 Safari/537.36'\n",
    "chrome_options = ChromeOptions()\n",
    "chrome_options.add_argument(f'user-agent={user_agent}')\n",
    "chrome_options.add_argument('--headless')\n",
    "\n",
    "# directory for meta data\n",
    "prefs = {\"download.default_directory\": intermediate_dir, \n",
    "         \"download.directory_upgrade\": True, \n",
    "         \"download.prompt_for_download\": False}\n",
    "chrome_options.add_experimental_option('prefs', prefs)\n",
    "\n",
    "# connect to redfin homepage\n",
    "url_redfin = 'https://www.redfin.com/'\n",
    "browser = webdriver.Chrome(options=chrome_options)\n",
    "browser.get(url_redfin)\n",
    "time.sleep(5)\n",
    "\n",
    "# login \n",
    "email = 'john.lukestein@gmail.com'\n",
    "password = 'redfin.0504'\n",
    "login_to_redfin(browser, email, password)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Updated albuquerque.csv\n",
      "Created alexandria.csv\n",
      "Created anchorage.csv\n",
      "Created arlington.csv\n",
      "Created ashburn.csv\n",
      "Created aurora.csv\n",
      "Created bakersfield.csv\n",
      "Created baltimore.csv\n",
      "Created baton_rouge.csv\n",
      "Created beaverton.csv\n",
      "Created bend.csv\n",
      "Created birmingham.csv\n",
      "Created boca_raton.csv\n",
      "Created boise.csv\n",
      "Created boston.csv\n",
      "Created bowie.csv\n",
      "Created brentwood.csv\n",
      "Created buffalo.csv\n",
      "Created burlington.csv\n",
      "Created cape_coral.csv\n",
      "Created chandler.csv\n",
      "Created charleston.csv\n",
      "Created charlotte.csv\n",
      "Created chattanooga.csv\n",
      "Created chicago.csv\n",
      "Created cincinnati.csv\n",
      "Created columbia.csv\n",
      "Created columbus.csv\n",
      "Created dallas.csv\n",
      "Created des_moines.csv\n",
      "Created detroit.csv\n",
      "Created el_paso.csv\n",
      "Created eugene.csv\n",
      "Created fairfax.csv\n",
      "Created flagstaff.csv\n",
      "Created fort_lauderdale.csv\n",
      "Created fort_myers.csv\n",
      "Created fort_worth.csv\n",
      "Created frederick.csv\n",
      "Created fremont.csv\n",
      "Created frisco.csv\n",
      "Created gilbert.csv\n",
      "Created glenview.csv\n",
      "Created honolulu.csv\n",
      "Created houston.csv\n",
      "Created indianapolis.csv\n",
      "Created irvine.csv\n",
      "Created jacksonville.csv\n",
      "Created jersey_city.csv\n",
      "Created kansas_city.csv\n",
      "Created knoxville.csv\n",
      "Created little_rock.csv\n",
      "Created long_island.csv\n",
      "Created los_angeles.csv\n",
      "Created louisville.csv\n",
      "Created madison.csv\n",
      "Created manhattan.csv\n",
      "Created memphis.csv\n",
      "Created mesa.csv\n",
      "Created miami.csv\n",
      "Created milwaukee.csv\n",
      "Created minneapolis.csv\n",
      "Created myrtle_beach.csv\n",
      "Created naperville.csv\n",
      "Created naples.csv\n",
      "Created nashua.csv\n",
      "Created nashville.csv\n",
      "Created new_orleans.csv\n",
      "Created new_york.csv\n",
      "Created newton.csv\n",
      "Created oakland.csv\n",
      "Created oklahoma_city.csv\n",
      "Created omaha.csv\n",
      "Created orland_park.csv\n",
      "Created orlando.csv\n",
      "Created palm_springs.csv\n",
      "Created phoenix.csv\n",
      "Created pittsburgh.csv\n",
      "Created plainfield.csv\n",
      "Created plano.csv\n",
      "Created portland.csv\n",
      "Updated portland.csv\n",
      "Created providence.csv\n",
      "Created quincy.csv\n",
      "Created raleigh.csv\n",
      "Created rancho_cucamonga.csv\n",
      "Created richmond.csv\n",
      "Created riverside.csv\n",
      "Created rochester.csv\n",
      "Created salem.csv\n",
      "Created salt_lake_city.csv\n",
      "Created san_antonio.csv\n",
      "Created san_diego.csv\n",
      "Created san_francisco.csv\n",
      "Created san_jose.csv\n",
      "Created san_luis_obispo.csv\n",
      "Created santa_clarita.csv\n",
      "Created santa_fe.csv\n",
      "Created sarasota.csv\n",
      "Created savannah.csv\n",
      "Created schaumburg.csv\n",
      "Created scottsdale.csv\n",
      "Created seattle.csv\n",
      "Created silver_spring.csv\n",
      "Created sioux_falls.csv\n",
      "Created st_louis.csv\n",
      "Created stamford.csv\n",
      "Created tacoma.csv\n",
      "Created tampa.csv\n",
      "Created temecula.csv\n",
      "Created tulsa.csv\n",
      "Created washington,_dc.csv\n",
      "Created west_palm_beach.csv\n",
      "Created woodbridge.csv\n",
      "Created worcester.csv\n"
     ]
    }
   ],
   "source": [
    "# cities links\n",
    "city = dict()\n",
    "city['names'], city['links'] = get_cities_links(browser)\n",
    "\n",
    "# get data\n",
    "for name, link in zip(city['names'], city['links']):\n",
    "    browser.get(link)\n",
    "    time.sleep(1)\n",
    "    \n",
    "    # download csv if available\n",
    "    try:\n",
    "        browser.find_element(By.XPATH, \"//a[text()='(Download All)']\").click()\n",
    "        time.sleep(1)\n",
    "\n",
    "        #\n",
    "        transfomer = CSV_Transformer(intermediate_dir, target_dir, name)\n",
    "        transfomer.transform()\n",
    "    # when it's not available\n",
    "    except:\n",
    "        with open('../resource/data/csv/web_scrapping/links.csv', 'a+') as f:\n",
    "            reader = csv.reader(f, delimiter=',')\n",
    "            writer = csv.writer(f)\n",
    "\n",
    "            # add new row if not existing\n",
    "            existing_rows = [row for row in reader]\n",
    "            current_row = [name, link]\n",
    "            if current_row not in existing_rows:\n",
    "                writer.writerow(current_row)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "web_scrapping",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
