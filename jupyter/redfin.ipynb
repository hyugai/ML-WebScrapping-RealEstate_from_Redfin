{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preparation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>Libraries</b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# bs4\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "# selenium\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver import ChromeOptions\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.support.ui import Select\n",
    "from selenium.webdriver.chrome.webdriver import WebDriver\n",
    "from selenium.webdriver.remote.webelement import WebElement\n",
    "\n",
    "# data structures\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# database\n",
    "import sqlite3\n",
    "import csv\n",
    "\n",
    "# others\n",
    "import sys, os, re, glob, datetime, time\n",
    "from lxml import etree\n",
    "\n",
    "# API keys\n",
    "cwd = os.getcwd()\n",
    "os.chdir('../'); src_path = os.getcwd()\n",
    "os.chdir(cwd)\n",
    "if src_path not in sys.path:\n",
    "    sys.path.append(src_path)\n",
    "from src import redfin_config"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>UDF</b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# login to redfin\n",
    "def login_to_redfin(browser: WebDriver, email: str, password: str) -> None:\n",
    "    time.sleep(5)\n",
    "    # begin logging\n",
    "    browser.find_element(By.XPATH, \"//span[text()='Join / Sign in']/..\").click()\n",
    "    \n",
    "    # email\n",
    "    time.sleep(1)\n",
    "    browser.find_element(By.XPATH, \"//input[@name='emailInput']\").send_keys(email)\n",
    "    browser.find_element(By.XPATH, \"//span[text()='Continue with Email']/..\").click()\n",
    "\n",
    "    # password\n",
    "    time.sleep(1)\n",
    "    browser.find_element(By.XPATH, \"//input[@name='passwordInput']\").send_keys(password)\n",
    "    browser.find_element(By.XPATH, \"//span[text()='Continue with Email']/..\").click()\n",
    "\n",
    "    return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get links to cities' pages\n",
    "def get_cities_links(browser: WebDriver) -> tuple[list, list]:\n",
    "    time.sleep(1)\n",
    "    # get list of cities\n",
    "    cities = browser.find_elements(By.XPATH, f\"//span[text()='Search for homes by city']/following-sibling::ul/child::li\")\n",
    "    \n",
    "    # 'show more' button to get all the names of cities\n",
    "    try:\n",
    "        browser.find_element(By.XPATH, \"//span[text()='Search for homes by city']/parent::*//span[text()='Show more']\").click()\n",
    "    except:\n",
    "        pass\n",
    "\n",
    "    # get link for each city\n",
    "    def _adjust_format(web_ele: WebElement) -> str:\n",
    "        text = web_ele.text.strip().lower()\\\n",
    "            .replace(' real estate', '')\\\n",
    "                .replace(' ', '_')\\\n",
    "                    .replace('.', '')\n",
    "        return text\n",
    "    names = list(map(_adjust_format, cities))\n",
    "    links = [city.find_element(By.XPATH, \".//child::a\").get_attribute('href') for city in cities]\n",
    "\n",
    "    return names, links"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def write_differ(writer, existing_rows: list, current_row: list) -> bool:\n",
    "    flag = all(list(map(lambda x: x == current_row, existing_rows)))\n",
    "    if flag:\n",
    "        writer.writerows([current_row])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>UDC</b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CSV_Transformer():\n",
    "    def __init__(self, intermediate_dir: str, target_dir: str, fixed_name: str) -> None:\n",
    "        self.intermediate_dir = intermediate_dir\n",
    "        self.target_dir = target_dir\n",
    "        self.fixed_name = fixed_name\n",
    "\n",
    "    # clear intermediate directory\n",
    "    def _cldir(self):\n",
    "        files_names = os.listdir(self.intermediate_dir)\n",
    "        for name in files_names:\n",
    "            os.remove(f'{self.intermediate_dir}/{name}')\n",
    "\n",
    "    # write difference\n",
    "    def _write_difference(self, existing_rows: list, current_rows: list):\n",
    "        rows_to_add = []\n",
    "        for row in current_rows:\n",
    "            flag = all(list(map(lambda x: x == row, existing_rows)))\n",
    "            if flag:\n",
    "                rows_to_add.append(row)\n",
    "\n",
    "        return rows_to_add\n",
    "\n",
    "    # create a new file\n",
    "    def _create_new_file(self):\n",
    "        try:\n",
    "            # get selected rows except the 2nd row\n",
    "            file_name = os.listdir(self.intermediate_dir)[0]\n",
    "            with open(f'{self.intermediate_dir}/{file_name}', 'r+') as f:\n",
    "                reader = csv.reader(f, delimiter=',')\n",
    "                rows = [row for i, row in enumerate(reader) if i != 1]\n",
    "\n",
    "            # add new csv file\n",
    "            with open(f'{self.target_dir}/{self.fixed_name}.csv', 'w+') as f:\n",
    "                writer = csv.writer(f)\n",
    "                writer.writerows(rows)\n",
    "\n",
    "        except Exception as e:\n",
    "            print(e)\n",
    "\n",
    "    # update an existing file\n",
    "    def _update_file(self):\n",
    "        # reading the existing file\n",
    "        with open(f'{self.target_dir}/{self.fixed_name}.csv', 'r+') as f:\n",
    "            reader = csv.reader(f, delimiter=',')\n",
    "            existing_rows = [row for row in reader]\n",
    "\n",
    "        # reading the downloaded file\n",
    "        try:\n",
    "            # get new rows to add\n",
    "            file_name = os.listdir(self.intermediate_dir)[0]\n",
    "            with open(f'{self.intermediate_dir}/{file_name}', 'r+') as f:\n",
    "                reader = csv.reader(f, delimiter=',')\n",
    "                current_rows = [row for i, row in enumerate(reader) if i != 1]\n",
    "                new_rows = self._write_difference(existing_rows, current_rows)\n",
    "\n",
    "            # append new rows to the existing file if available\n",
    "            if new_rows:\n",
    "                with open(f'{self.target_dir}/{self.fixed_name}.csv', 'a+') as f:\n",
    "                    writer = csv.writer(f)\n",
    "                    writer.writerows(new_rows)\n",
    "        except Exception as e:\n",
    "            print(e)\n",
    "\n",
    "    # transform content inside\n",
    "    def transform(self):\n",
    "        # available \n",
    "        if not os.path.exists(f'{self.target_dir}/{self.fixed_name}.csv'):\n",
    "            self._create_new_file()\n",
    "            print(f'Created {self.fixed_name}.csv')\n",
    "        \n",
    "        # unavailable\n",
    "        else:\n",
    "            self._update_file()\n",
    "            print(f'Updated {self.fixed_name}.csv')\n",
    "\n",
    "        # clear files for new iteration\n",
    "        self._cldir()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# \n",
    "class RedfinHeadlessChromeBrowser():\n",
    "    def __init__(\n",
    "            self,\n",
    "            default_download_dir: str, EMAIL: str, PASSWORD: str,\n",
    "            user_agent: str=r'Mozilla/5.0 (X11; Linux x86_64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/60.0.3112.50 Safari/537.36', \n",
    "            homepage_redfin_url: str=r'https://www.redfin.com/'\n",
    "    ) -> None:\n",
    "        self.default_download_dir = default_download_dir\n",
    "        self.user_agent = user_agent\n",
    "        self.homepage_redfin_url = homepage_redfin_url\n",
    "        self.EMAIL = EMAIL; self.PASSWORD = PASSWORD\n",
    "\n",
    "    # open website\n",
    "    def _open_redfin_website(self):\n",
    "        # \n",
    "        chrome_options = ChromeOptions()\n",
    "        chrome_options.add_argument(f'user-agent={self.user_agent}')\n",
    "        chrome_options.add_argument('--headless')\n",
    "        #\n",
    "        prefs = {\"download.default_directory\": self.default_download_dir, \n",
    "                 \"download.directory_upgrade\": True, \n",
    "                 \"download.prompt_for_download\": False}\n",
    "        chrome_options.add_experimental_option('prefs', prefs)\n",
    "        # \n",
    "        self.browser = webdriver.Chrome(options=chrome_options)\n",
    "        self.browser.get(self.homepage_redfin_url)\n",
    "\n",
    "        return self\n",
    "    # log in to redfin account\n",
    "    def _log_in_to_redfin_account(self) -> None:\n",
    "        time.sleep(5)\n",
    "        # begin logging\n",
    "        self.browser.find_element(By.XPATH, \"//span[text()='Join / Sign in']/..\").click()\n",
    "        \n",
    "        # email\n",
    "        time.sleep(1)\n",
    "        self.browser.find_element(By.XPATH, \"//input[@name='emailInput']\").send_keys(self.EMAIL)\n",
    "        self.browser.find_element(By.XPATH, \"//span[text()='Continue with Email']/..\").click()\n",
    "\n",
    "        # password\n",
    "        time.sleep(1)\n",
    "        self.browser.find_element(By.XPATH, \"//input[@name='passwordInput']\").send_keys(self.PASSWORD)\n",
    "        self.browser.find_element(By.XPATH, \"//span[text()='Continue with Email']/..\").click()\n",
    "\n",
    "    # return brower\n",
    "    def get_logged_in_browser(self) -> None:\n",
    "        self._open_redfin_website()\n",
    "        self._log_in_to_redfin_account()\n",
    "    \n",
    "    # quit browser\n",
    "    def quit_browser(self) -> None:\n",
    "        self.browser.quit()\n",
    "\n",
    "    # return to homepage\n",
    "    def return_to_homepage(self) -> None:\n",
    "        self.browser.get(self.homepage_redfin_url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# \n",
    "class CSVLoaderFromAPI():\n",
    "    def __init__(self, paths: dict, redfin: RedfinHeadlessChromeBrowser) -> None:\n",
    "        self.paths = paths\n",
    "        self.redfin = redfin\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# \n",
    "class CSVLoaderFromScrapping():\n",
    "    def __init__(self, paths: dict, redfin: RedfinHeadlessChromeBrowser) -> None:\n",
    "        self.paths = paths\n",
    "        self.redfin = redfin "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# \n",
    "class RedfinScrapper():\n",
    "    def __init__(self, paths: dict, redfin: RedfinHeadlessChromeBrowser) -> None:\n",
    "        self.paths = paths\n",
    "        self.redfin = redfin\n",
    "\n",
    "    def _create_db(self) -> None:\n",
    "        with sqlite3.connect(f\"{self.paths['target']}/urls.db\") as conn:\n",
    "            cur = conn.cursor()\n",
    "            cur.executescript('\\\n",
    "                        CREATE TABLE IF NOT EXISTS urls(\\\n",
    "                                                        city TEXT UNIQUE, url TEXT, csv_download_link TEXT)')\n",
    "            cur.close()\n",
    "\n",
    "    def _get_city_urls(self) -> None:\n",
    "        time.sleep(1)\n",
    "        # get tags\n",
    "        title = self.redfin.browser.find_element(By.XPATH, \"//span[text()='Search for homes by city']\")\n",
    "        try:\n",
    "            title.find_element(By.XPATH, \"./parent::*/descendant::span[text()='Show more']\").click()\n",
    "        except:\n",
    "            pass\n",
    "        city_list = title.find_elements(By.XPATH, \"./parent::*/descendant::li[@class='city']\")\n",
    "\n",
    "        # get names & links\n",
    "        city = list()\n",
    "        for li in city_list:\n",
    "            tag = li.find_element(By.XPATH, \".//child::a\")\n",
    "            name = tag.text.lower().strip().replace(' real estate', '')\n",
    "            link = tag.get_attribute('href')\n",
    "            state_abbreviation = re.search(r\"[A-Z]{2}\", link).group()\n",
    "            city.append([f\"{name}_{state_abbreviation}\", link])\n",
    "        self.city = city\n",
    "            \n",
    "    # \n",
    "    def _get_available_csv_download_link(self) -> None:\n",
    "        csv_download_links = list()\n",
    "        for city_name, city_link in self.city[:2]:\n",
    "            try:\n",
    "                self.redfin.browser.get(city_link)\n",
    "                time.sleep(1)\n",
    "                csv_link = self.redfin.browser.find_element(By.XPATH, \"//a[text()='(Download All)']\")\\\n",
    "                    .get_attribute('href')\n",
    "                csv_download_links.append([city_name, city_link, csv_link])\n",
    "            except:\n",
    "                csv_download_links.append([city_name, city_link, None])\n",
    "\n",
    "        # \n",
    "        with sqlite3.connect(f\"{self.paths['target']}/urls.db\") as conn:\n",
    "            cur = conn.cursor()\n",
    "            for row in csv_download_links:\n",
    "                cur.execute(f'\\\n",
    "                            INSERT OR REPLACE INTO urls VALUES(?, ?, ?)', tuple(row))\n",
    "            cur.close()\n",
    "\n",
    "    def start_scrapping(self) -> None:\n",
    "        self._create_db()\n",
    "        self._get_city_urls()\n",
    "        self._get_available_csv_download_link()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Selenium"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>Preparation</b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# header: user-agent\n",
    "user_agent = 'Mozilla/5.0 (X11; Linux x86_64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/60.0.3112.50 Safari/537.36'\n",
    "# options\n",
    "chrome_options = ChromeOptions()\n",
    "chrome_options.add_argument(f'user-agent={user_agent}')\n",
    "# browser\n",
    "url_redfin = 'https://www.redfin.com/'\n",
    "browser = webdriver.Chrome(options=chrome_options)\n",
    "browser.get(url_redfin)\n",
    "time.sleep(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[38], line 4\u001b[0m\n\u001b[1;32m      2\u001b[0m email \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mjohn.lukestein@gmail.com\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m      3\u001b[0m password \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mredfin.0504\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m----> 4\u001b[0m \u001b[43mlogin_to_redfin\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbrowser\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43memail\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpassword\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[29], line 3\u001b[0m, in \u001b[0;36mlogin_to_redfin\u001b[0;34m(browser, email, password)\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mlogin_to_redfin\u001b[39m(browser: WebDriver, email: \u001b[38;5;28mstr\u001b[39m, password: \u001b[38;5;28mstr\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m----> 3\u001b[0m     \u001b[43mtime\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msleep\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m5\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m      4\u001b[0m     \u001b[38;5;66;03m# begin logging\u001b[39;00m\n\u001b[1;32m      5\u001b[0m     browser\u001b[38;5;241m.\u001b[39mfind_element(By\u001b[38;5;241m.\u001b[39mXPATH, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m//span[text()=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mJoin / Sign in\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m]/..\u001b[39m\u001b[38;5;124m\"\u001b[39m)\u001b[38;5;241m.\u001b[39mclick()\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# redfin logging\n",
    "email = 'john.lukestein@gmail.com'\n",
    "password = 'redfin.0504'\n",
    "login_to_redfin(browser, email, password)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>Store Data as CSV</b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# prepare directories\n",
    "cwd = os.getcwd()\n",
    "# intermediate\n",
    "os.chdir('../resource/temp')\n",
    "intermediate_dir=os.getcwd()\n",
    "\n",
    "# target \n",
    "os.chdir('../data/csv/api')\n",
    "target_dir = os.getcwd()\n",
    "os.chdir(cwd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# options for browser\n",
    "user_agent = r'Mozilla/5.0 (X11; Linux x86_64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/60.0.3112.50 Safari/537.36'\n",
    "chrome_options = ChromeOptions()\n",
    "chrome_options.add_argument(f'user-agent={user_agent}')\n",
    "chrome_options.add_argument('--headless')\n",
    "\n",
    "# directory for meta data\n",
    "prefs = {\"download.default_directory\": intermediate_dir, \n",
    "         \"download.directory_upgrade\": True, \n",
    "         \"download.prompt_for_download\": False}\n",
    "chrome_options.add_experimental_option('prefs', prefs)\n",
    "\n",
    "# connect to redfin homepage\n",
    "url_redfin = 'https://www.redfin.com/'\n",
    "browser = webdriver.Chrome(options=chrome_options)\n",
    "browser.get(url_redfin)\n",
    "time.sleep(5)\n",
    "\n",
    "# login \n",
    "email = 'john.lukestein@gmail.com'\n",
    "password = 'redfin.0504'\n",
    "login_to_redfin(browser, email, password)\n",
    "\n",
    "# directory for meta data\n",
    "prefs = {\"download.default_directory\": intermediate_dir, \n",
    "         \"download.directory_upgrade\": True, \n",
    "         \"download.prompt_for_download\": False}\n",
    "chrome_options.add_experimental_option('prefs', prefs)\n",
    "\n",
    "# connect to redfin homepage\n",
    "url_redfin = 'https://www.redfin.com/'\n",
    "browser = webdriver.Chrome(options=chrome_options)\n",
    "browser.get(url_redfin)\n",
    "time.sleep(5)\n",
    "\n",
    "# login \n",
    "email = 'john.lukestein@gmail.com'\n",
    "password = 'redfin.0504'\n",
    "login_to_redfin(browser, email, password)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Created albuquerque.csv\n",
      "Created alexandria.csv\n",
      "Created anchorage.csv\n",
      "Created arlington.csv\n",
      "Created ashburn.csv\n",
      "Created aurora.csv\n",
      "Created bakersfield.csv\n",
      "Created baltimore.csv\n",
      "Created baton_rouge.csv\n",
      "Created beaverton.csv\n",
      "Created bend.csv\n",
      "Created birmingham.csv\n",
      "Created boca_raton.csv\n",
      "Created boise.csv\n",
      "Created boston.csv\n",
      "Created bowie.csv\n",
      "Created brentwood.csv\n",
      "Created buffalo.csv\n",
      "Created burlington.csv\n",
      "Created cape_coral.csv\n",
      "Created chandler.csv\n",
      "Created charleston.csv\n",
      "Created charlotte.csv\n",
      "Created chattanooga.csv\n",
      "Created chicago.csv\n",
      "Created cincinnati.csv\n",
      "Created columbia.csv\n",
      "Created columbus.csv\n",
      "Created dallas.csv\n",
      "Created des_moines.csv\n",
      "Created detroit.csv\n",
      "Created el_paso.csv\n",
      "Created eugene.csv\n",
      "Created fairfax.csv\n",
      "Created flagstaff.csv\n",
      "Created fort_lauderdale.csv\n",
      "Created fort_myers.csv\n",
      "Created fort_worth.csv\n",
      "Created frederick.csv\n",
      "Created fremont.csv\n",
      "Created frisco.csv\n",
      "Created gilbert.csv\n",
      "Created glenview.csv\n",
      "Created honolulu.csv\n",
      "Created houston.csv\n",
      "Created indianapolis.csv\n",
      "Created irvine.csv\n",
      "Created jacksonville.csv\n",
      "Created jersey_city.csv\n",
      "Created kansas_city.csv\n",
      "Created knoxville.csv\n",
      "Created little_rock.csv\n",
      "Created long_island.csv\n",
      "Created los_angeles.csv\n",
      "Created louisville.csv\n",
      "Created madison.csv\n",
      "Created manhattan.csv\n",
      "Created memphis.csv\n",
      "Created mesa.csv\n",
      "Created miami.csv\n",
      "Created milwaukee.csv\n",
      "Created minneapolis.csv\n",
      "Created myrtle_beach.csv\n",
      "Created naperville.csv\n",
      "Created naples.csv\n",
      "Created nashua.csv\n",
      "Created nashville.csv\n",
      "Created new_orleans.csv\n",
      "Created new_york.csv\n",
      "Created newton.csv\n",
      "Created oakland.csv\n",
      "Created oklahoma_city.csv\n",
      "Created omaha.csv\n",
      "Created orland_park.csv\n",
      "Created orlando.csv\n",
      "Created palm_springs.csv\n",
      "Created phoenix.csv\n",
      "Created pittsburgh.csv\n",
      "Created plainfield.csv\n",
      "Created plano.csv\n",
      "Created portland.csv\n",
      "Updated portland.csv\n",
      "Created providence.csv\n",
      "Created quincy.csv\n",
      "Created raleigh.csv\n",
      "Created rancho_cucamonga.csv\n",
      "Created richmond.csv\n",
      "Created riverside.csv\n",
      "Created rochester.csv\n",
      "Created salem.csv\n",
      "Created salt_lake_city.csv\n",
      "Created san_antonio.csv\n",
      "Created san_diego.csv\n",
      "Created san_francisco.csv\n",
      "Created san_jose.csv\n",
      "Created san_luis_obispo.csv\n",
      "Created santa_clarita.csv\n",
      "Created santa_fe.csv\n",
      "Created sarasota.csv\n",
      "Created savannah.csv\n",
      "Created schaumburg.csv\n",
      "Created scottsdale.csv\n",
      "Created seattle.csv\n",
      "Created silver_spring.csv\n",
      "Created sioux_falls.csv\n",
      "Created st_louis.csv\n",
      "Created stamford.csv\n",
      "Created tacoma.csv\n",
      "Created tampa.csv\n",
      "Created temecula.csv\n",
      "Created tulsa.csv\n",
      "Created washington,_dc.csv\n",
      "Created west_palm_beach.csv\n",
      "Created woodbridge.csv\n",
      "Created worcester.csv\n"
     ]
    }
   ],
   "source": [
    "# cities links\n",
    "city = dict()\n",
    "city['names'], city['links'] = get_cities_links(browser)\n",
    "\n",
    "# get data\n",
    "for name, city_link in zip(city['names'], city['links']):\n",
    "    browser.get(city_link)\n",
    "    transfomer = CSV_Transformer(intermediate_dir, target_dir, name)\n",
    "    time.sleep(1)\n",
    "    \n",
    "    # download csv if available\n",
    "    try:\n",
    "        # click download button\n",
    "        download_button = browser.find_element(By.XPATH, \"//a[text()='(Download All)']\")\n",
    "        download_button.click()\n",
    "        time.sleep(1)\n",
    "\n",
    "        # save download link for later usage\n",
    "        download_link = download_button.get_attribute('href')\n",
    "        with open('../resource/data/csv/api/links.csv', 'a+') as f:\n",
    "            reader, writer = csv.reader(f, delimiter='r'), csv.writer(f, delimiter=',')\n",
    "            existing_rows, current_row = [row for row in reader], [[name, download_link]]\n",
    "            new_row = transfomer._write_difference(existing_rows, current_row)\n",
    "            if new_row:\n",
    "                writer.writerow(new_row[0])\n",
    "\n",
    "        # process and push the csv file to the target directory\n",
    "        transfomer.transform()\n",
    "\n",
    "    # when it's not available\n",
    "    except:\n",
    "        # save city for later usage\n",
    "        with open('../resource/data/csv/web_scrapping/links.csv', 'a+') as f:\n",
    "            reader, writer = csv.reader(f, delimiter=','), csv.writer(f, delimiter=',')\n",
    "            existing_rows, current_row = [row for row in reader], [[name, city_link]]\n",
    "            new_row = transfomer._write_difference(existing_rows, current_row)\n",
    "            if new_row:\n",
    "                writer.writerow(new_row[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "browser.quit()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>Draft</b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "with requests.Session() as s:\n",
    "    # get respone of the GET request\n",
    "    user_agent = r'Mozilla/5.0 (X11; Linux x86_64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/60.0.3112.50 Safari/537.36'\n",
    "    headers = {'User-Agent': user_agent}\n",
    "    test_url = 'https://www.redfin.com/city/30818/TX/Austin'\n",
    "    r = s.get(test_url, headers=headers)\n",
    "\n",
    "    # soup\n",
    "    soup = BeautifulSoup(r.content)\n",
    "\n",
    "    # DOM object\n",
    "    dom = etree.HTML(str(soup))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'@context': 'http://schema.org',\n",
       " 'name': '11516 Oltons Bluff Cv, Austin, TX 78754',\n",
       " 'url': 'https://www.redfin.com/TX/Austin/11516-Oltons-Bluff-Cv-78754/home/31090991',\n",
       " 'address': {'@type': 'PostalAddress',\n",
       "  'streetAddress': '11516 Oltons Bluff Cv',\n",
       "  'addressLocality': 'Austin',\n",
       "  'addressRegion': 'TX',\n",
       "  'postalCode': '78754',\n",
       "  'addressCountry': 'US'},\n",
       " 'geo': {'@type': 'GeoCoordinates',\n",
       "  'latitude': 30.3748589,\n",
       "  'longitude': -97.6482833},\n",
       " 'numberOfRooms': 3,\n",
       " 'floorSize': {'@type': 'QuantitativeValue', 'value': 2476, 'unitCode': 'FTK'},\n",
       " '@type': 'SingleFamilyResidence'}"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "map_home_cards = dom.xpath(\"//div[contains(@id, 'MapHomeCard')]\")\n",
    "eval(map_home_cards[0].xpath(\".//descendant::script\")[0].text)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'mlsId': {'label': 'MLS#', 'value': '6723436'},\n",
       " 'showMlsId': False,\n",
       " 'mlsStatus': 'Active',\n",
       " 'showDatasourceLogo': False,\n",
       " 'price': {'value': 435000, 'level': 1},\n",
       " 'hideSalePrice': False,\n",
       " 'hoa': {'value': 20, 'level': 1},\n",
       " 'isHoaFrequencyKnown': True,\n",
       " 'sqFt': {'value': 2476, 'level': 1},\n",
       " 'pricePerSqFt': {'value': 176, 'level': 1},\n",
       " 'lotSize': {'value': 8132, 'level': 1},\n",
       " 'beds': 3,\n",
       " 'baths': 2.5,\n",
       " 'fullBaths': 2,\n",
       " 'partialBaths': 1,\n",
       " 'location': {'value': 'Pioneer Crossing West Sec 07', 'level': 1},\n",
       " 'stories': 2.0,\n",
       " 'latLong': {'value': {'latitude': 30.3748589, 'longitude': -97.6482833},\n",
       "  'level': 1},\n",
       " 'streetLine': {'value': '11516 Oltons Bluff Cv', 'level': 1},\n",
       " 'unitNumber': {'level': 1},\n",
       " 'city': 'Austin',\n",
       " 'state': 'TX',\n",
       " 'zip': '78754',\n",
       " 'postalCode': {'value': '78754', 'level': 1},\n",
       " 'countryCode': 'US',\n",
       " 'showAddressOnMap': True,\n",
       " 'soldDate': 1184828400000,\n",
       " 'searchStatus': 1,\n",
       " 'propertyType': 6,\n",
       " 'uiPropertyType': 1,\n",
       " 'listingType': 1,\n",
       " 'propertyId': 31090991,\n",
       " 'listingId': 193379250,\n",
       " 'dataSourceId': 92,\n",
       " 'marketId': 12,\n",
       " 'yearBuilt': {'value': 2007, 'level': 1},\n",
       " 'dom': {'value': 1, 'level': 1},\n",
       " 'timeOnRedfin': {'value': 43844795, 'level': 1},\n",
       " 'originalTimeOnRedfin': {'value': 43844807, 'level': 1},\n",
       " 'timeZone': 'USu002FCentral',\n",
       " 'primaryPhotoDisplayLevel': 1,\n",
       " 'photos': {'value': '0-39:0', 'level': 1},\n",
       " 'alternatePhotosInfo': {'mediaListType': '1',\n",
       "  'mediaListIndex': 0,\n",
       "  'groupCode': '991109_JPG',\n",
       "  'positionSpec': [1,\n",
       "   3,\n",
       "   5,\n",
       "   8,\n",
       "   9,\n",
       "   10,\n",
       "   11,\n",
       "   12,\n",
       "   13,\n",
       "   14,\n",
       "   15,\n",
       "   16,\n",
       "   17,\n",
       "   18,\n",
       "   19,\n",
       "   20,\n",
       "   21,\n",
       "   22,\n",
       "   23,\n",
       "   24,\n",
       "   25,\n",
       "   26,\n",
       "   27,\n",
       "   28,\n",
       "   6,\n",
       "   29,\n",
       "   30,\n",
       "   32,\n",
       "   33,\n",
       "   35,\n",
       "   36,\n",
       "   38,\n",
       "   39,\n",
       "   40,\n",
       "   42,\n",
       "   41,\n",
       "   43,\n",
       "   44,\n",
       "   45,\n",
       "   49],\n",
       "  'type': 1},\n",
       " 'additionalPhotosInfo': [],\n",
       " 'listingAgent': {'name': 'Michael Condrey', 'redfinAgentId': 30677},\n",
       " 'openHouseStart': 1726934400000,\n",
       " 'openHouseEnd': 1726941600000,\n",
       " 'openHouseStartFormatted': 'Sep 21, 11:00AM',\n",
       " 'openHouseEventName': 'Open House - 11:00 - 1:00 PM',\n",
       " 'url': 'u002FTXu002FAustinu002F11516-Oltons-Bluff-Cv-78754u002Fhomeu002F31090991',\n",
       " 'hasInsight': False,\n",
       " 'sashes': [{'sashType': 10,\n",
       "   'sashTypeId': 10,\n",
       "   'sashTypeName': 'Open House',\n",
       "   'sashTypeColor': '#73BB3C',\n",
       "   'isRedfin': True,\n",
       "   'isActiveKeyListing': False,\n",
       "   'openHouseText': 'OPEN SAT, 11AM TO 1PM',\n",
       "   'lastSaleDate': '',\n",
       "   'lastSalePrice': ''},\n",
       "  {'sashType': 31,\n",
       "   'sashTypeId': 31,\n",
       "   'sashTypeName': '3D Walkthrough',\n",
       "   'sashTypeColor': '#7556F2',\n",
       "   'isRedfin': False,\n",
       "   'isActiveKeyListing': False,\n",
       "   'openHouseText': '',\n",
       "   'lastSaleDate': '',\n",
       "   'lastSalePrice': ''}],\n",
       " 'keyFacts': [{'description': '8,132 sq ft lot', 'rank': 0},\n",
       "  {'description': '$20 HOA', 'rank': 1},\n",
       "  {'description': '2 garage spots', 'rank': 2}],\n",
       " 'isHot': False,\n",
       " 'hasVirtualTour': True,\n",
       " 'hasVideoTour': False,\n",
       " 'has3DTour': True,\n",
       " 'newConstructionCommunityInfo': {},\n",
       " 'isRedfin': True,\n",
       " 'isActiveKeyListing': False,\n",
       " 'isNewConstruction': False,\n",
       " 'listingRemarks': 'Welcome to your dream home in the heart of North Austin! This stunning 3-bedroom, 2.5-bathroom residence boasts 2,378 square feet of thoughtfully designed living space, perfect for modern family living. The moment you step inside, youu0026rsquo;ll appreciate the abundance of natural light and the elegant, low-maintenance flooring that flows throughout the homeu0026mdash;no carpet here!    The main floor features an open-concept layout, seamlessly connecting the spacious living area to the contemporary kitchen, ideal for both entertaining and everyday living. The kitchen is a chefu0026rsquo;s delight, equipped with ample counter space, modern appliances, and a breakfast bar, making it perfect for casual',\n",
       " 'remarksAccessLevel': 1,\n",
       " 'businessMarketId': 13,\n",
       " 'isShortlisted': False,\n",
       " 'isViewedListing': False}"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tag_content = re.sub(r'\\\\', '', dom.xpath(\"//script\")[-2].text)\n",
    "text = re.findall(r\"\\\"homes\\\":\\[[^'']*\\],\\\"dataSources\\\"\", tag_content)\n",
    "x1 = re.sub(r\",\\\"dataSources\\\"\",'', text[0])[8:]\n",
    "x2 = re.sub(r\"false\", \"False\", x1)\n",
    "x3 = re.sub(r\"true\", \"True\", x2)\n",
    "eval(x3)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('../resource/data/csv/api/alexandria.csv', 'r') as f:\n",
    "    reader = csv.reader(f)\n",
    "    test = list(reader)\n",
    "    line = test[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sale type\n",
      "sold date\n",
      "property type\n",
      "address\n",
      "city\n",
      "state or province\n",
      "zip or postal code\n",
      "price\n",
      "beds\n",
      "baths\n",
      "location\n",
      "square feet\n",
      "lot size\n",
      "year built\n",
      "days on market\n",
      "$/square feet\n",
      "hoa/month\n",
      "status\n",
      "next open house start time\n",
      "next open house end time\n",
      "url (see https://www.redfin.com/buy-a-home/comparative-market-analysis for info on pricing)\n",
      "source\n",
      "mls#\n",
      "favorite\n",
      "interested\n",
      "latitude\n",
      "longitude\n"
     ]
    }
   ],
   "source": [
    "for i in line:\n",
    "    x = i.lower().replace(r\"\\([^'']*\\)\", '')\n",
    "    print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['(see https://www.redfin.com/buy-a-home/comparative-market-analysis for info on pricing)']"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = 'URL (SEE https://www.redfin.com/buy-a-home/comparative-market-analysis FOR INFO ON PRICING)'\n",
    "re.findall(r\"\\([^'']*\\)\", x.lower())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'url'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "re.sub(r\"\\s\\([^'']*\\)\",'', x.lower())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2, '1.4')\n"
     ]
    }
   ],
   "source": [
    "x = ['col2', 'col1']\n",
    "y = [1.4, 2]\n",
    "with sqlite3.connect('../resource/data/test.db') as conn:\n",
    "    cur = conn.cursor()\n",
    "    cur.executescript('\\\n",
    "                      DROP TABLE IF EXISTS test;\\\n",
    "                      CREATE TABLE IF NOT EXISTS test(\\\n",
    "                        col1 INTEGER, col2 TEXT) STRICT')\n",
    "    cur.execute(f'\\\n",
    "                INSERT INTO test{tuple(x)}\\\n",
    "                    VALUES (?, ?)', tuple(y))\n",
    "    cur.execute('SELECT * FROM test')\n",
    "    for i in cur:\n",
    "        print(i)\n",
    "    cur.execute('DROP TABLE IF EXISTS test')\n",
    "    conn.commit()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>Draft ver 01</b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# prepare paths\n",
    "cwd = os.getcwd()\n",
    "os.chdir('../resource/data'); target = os.getcwd()\n",
    "os.chdir('../temp'); temp = os.getcwd()\n",
    "os.chdir(cwd)\n",
    "paths = {'target': target, 'temp': temp}\n",
    "\n",
    "# headless browser\n",
    "redfin = RedfinHeadlessChromeBrowser(paths['temp'], redfin_config.EMAIL, redfin_config.PASSWORD)\n",
    "redfin.get_logged_in_browser()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "scrapper = RedfinScrapper(paths, redfin)\n",
    "scrapper.start_scrapping()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n"
     ]
    }
   ],
   "source": [
    "with sqlite3.connect(f\"{paths['target']}/urls.db\") as conn:\n",
    "    cur = conn.cursor()\n",
    "    cur.execute('select * from urls')\n",
    "    rows = cur.fetchall()\n",
    "    conn.commit()\n",
    "    print(len(rows))\n",
    "    cur.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "web_scrapping",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
