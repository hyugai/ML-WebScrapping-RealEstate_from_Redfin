{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preparation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>Libraries</b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# bs4\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "# selenium\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver import ChromeOptions\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.support.ui import Select\n",
    "from selenium.webdriver.chrome.webdriver import WebDriver\n",
    "from selenium.webdriver.remote.webelement import WebElement\n",
    "\n",
    "# data structures\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# database\n",
    "import sqlite3\n",
    "import csv\n",
    "\n",
    "# others\n",
    "import sys, os, re, glob, datetime, time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>UDF</b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# login to redfin\n",
    "def login_to_redfin(browser: WebDriver, email: str, password: str) -> None:\n",
    "    time.sleep(5)\n",
    "    ## begin logging\n",
    "    browser.find_element(By.XPATH, \"//span[text()='Join / Sign in']/..\").click()\n",
    "    ## email\n",
    "    time.sleep(1)\n",
    "    browser.find_element(By.XPATH, \"//input[@name='emailInput']\").send_keys(email)\n",
    "    browser.find_element(By.XPATH, \"//span[text()='Continue with Email']/..\").click()\n",
    "    ## password\n",
    "    time.sleep(1)\n",
    "    browser.find_element(By.XPATH, \"//input[@name='passwordInput']\").send_keys(password)\n",
    "    browser.find_element(By.XPATH, \"//span[text()='Continue with Email']/..\").click()\n",
    "\n",
    "    return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get links to cities' pages\n",
    "def get_cities_links(browser: WebDriver) -> tuple[list, list]:\n",
    "    time.sleep(1)\n",
    "    ## get list of cities\n",
    "    cities = browser.find_elements(By.XPATH, f\"//span[text()='Search for homes by city']/following-sibling::ul/child::li\")\n",
    "    ## show more button to get all the names of cities\n",
    "    try:\n",
    "        browser.find_element(By.XPATH, \"//span[text()='Search for homes by city']/parent::*//span[text()='Show more']\").click()\n",
    "    except:\n",
    "        pass\n",
    "    ## get link for each city\n",
    "    names = list(map(lambda x: re.sub(' real estate', '', x.text.strip()), cities))\n",
    "    links = [city.find_element(By.XPATH, \".//child::a\").get_attribute('href') for city in cities]\n",
    "\n",
    "    return names, links"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get links to download the csv files\n",
    "def get_csv_link(browser: WebDriver) -> str:\n",
    "    link =  browser.find_element(By.XPATH, \"//a[text()='(Download All)']\").get_attribute('href')\n",
    "\n",
    "    return link"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>UDC</b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CSV_Transformer():\n",
    "    def __init__(self, intermediate_dir: str, target_dir: str, fixed_name: str) -> None:\n",
    "        self.intermediate_dir = intermediate_dir\n",
    "        self.target_dir = target_dir\n",
    "        self.fixed_name = fixed_name\n",
    "    def _cldir(self):\n",
    "        paths = os.listdir(self.intermediate_dir)\n",
    "        for path in paths:\n",
    "            os.remove(path)\n",
    "\n",
    "    def _new_file(self):\n",
    "        try:\n",
    "            path = os.listdir(self.intermediate_dir)[0]\n",
    "            ### get selected rows\n",
    "            with open(path, 'r+') as f:\n",
    "                reader = csv.reader(f, delimiter=',')\n",
    "                rows = [row for i, row in enumerate(reader) if i != 1]\n",
    "\n",
    "            ### new csv file\n",
    "            with open(f'{self.target_dir}/{self.fixed_name}.csv', 'w+') as f:\n",
    "                writer = csv.writer(f)\n",
    "                writer.writerows(rows)\n",
    "\n",
    "        except Exception as e:\n",
    "            print(e)\n",
    "\n",
    "    def _existing_file(self):\n",
    "        with open(f'{self.target_dir}/{self.fixed_name}.csv', 'r+') as f:\n",
    "            reader = csv.reader(f, delimiter=',')\n",
    "            existing_rows = [row for row in reader]\n",
    "\n",
    "        try:\n",
    "            path = os.listdir()[0]\n",
    "            with open(path, 'r+') as f:\n",
    "                reader = csv.reader(f, delimiter=',')\n",
    "                new_rows = [row for row in reader if row not in existing_rows]\n",
    "\n",
    "            ### append new rows to the existing file\n",
    "            with open(f'{self.target_dir}/{self.fixed_name}.csv', 'a+') as f:\n",
    "                writer = csv.writer(f)\n",
    "                writer.writerows(new_rows)\n",
    "        except Exception as e:\n",
    "            print(e)\n",
    "\n",
    "    ## transform content inside\n",
    "    def transform(self):\n",
    "        if not os.path.exists(f'{self.target_dir}/{self.fixed_name}.csv'):\n",
    "            self._new_file()\n",
    "        else:\n",
    "            self._existing_file()\n",
    "\n",
    "        # clear files for new iteration\n",
    "        self._cldir()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Selenium"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>Preparation</b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# header: user-agent\n",
    "user_agent = 'Mozilla/5.0 (X11; Linux x86_64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/60.0.3112.50 Safari/537.36'\n",
    "# options\n",
    "chrome_options = ChromeOptions()\n",
    "chrome_options.add_argument(f'user-agent={user_agent}')\n",
    "# browser\n",
    "url_redfin = 'https://www.redfin.com/'\n",
    "browser = webdriver.Chrome(options=chrome_options)\n",
    "browser.get(url_redfin)\n",
    "time.sleep(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# redfin logging\n",
    "email = 'john.lukestein@gmail.com'\n",
    "password = 'redfin.0504'\n",
    "login_to_redfin(browser, email, password)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>Store csv links as a txt file</b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "# store links downloading csv files in a txt file\n",
    "cities_links = get_cities_links(browser)\n",
    "for link in cities_links:\n",
    "    browser.get(link)\n",
    "    time.sleep(1)\n",
    "    try:\n",
    "        link = get_csv_link(browser)\n",
    "        with open('../resource/data/csv_links.txt', 'a') as f:\n",
    "            f.write(f'{link}\\n')\n",
    "    except:\n",
    "        with open('../resource/data/failed_to_get_csv_link.txt', 'a') as f:\n",
    "            f.write(f'{link}\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>Store csv links as a table using SQLite</b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get csv links\n",
    "## \n",
    "cities = {'names': None, 'links': None}\n",
    "cities['names'], cities['links'] = get_cities_links(browser)\n",
    "##\n",
    "with sqlite3.connect(r'../resource/data/homes_by_city.db') as conn:\n",
    "    cursor = conn.cursor()\n",
    "    cursor.execute('CREATE TABLE IF NOT EXISTS csv_links (id INTEGER PRIMARY KEY, \\\n",
    "                                                            name TEXT, \\\n",
    "                                                            available INTEGER, \\\n",
    "                                                            link TEXT, \\\n",
    "                                                            scrapped_time TEXT)')\n",
    "    conn.commit()\n",
    "    ### insert data to table\n",
    "    for name, city_link in zip(cities['names'], cities['links']):\n",
    "        ###\n",
    "        browser.get(city_link)\n",
    "        time.sleep(1)\n",
    "        scrapped_time = datetime.datetime.now().strftime(r'%Y-%m-%d %H:%M:%S')\n",
    "        ###\n",
    "        try:\n",
    "            csv_link = get_csv_link(browser)\n",
    "            cursor.execute(\"INSERT INTO csv_links (name, available, link, scrapped_time) \\\n",
    "                                VALUES (?, ?, ?, ?)\", (name, 1, csv_link, scrapped_time))\n",
    "            conn.commit()\n",
    "        except:\n",
    "            cursor.execute(\"INSERT INTO csv_links (name, available, link, scrapped_time)\\\n",
    "                                VALUES (?, ?, ?, ?)\", (name, 0, city_link, scrapped_time))\n",
    "            conn.commit()\n",
    "\n",
    "    cursor.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>Load data from csv links</b>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>Draft</b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "## options for browser\n",
    "user_agent = r'Mozilla/5.0 (X11; Linux x86_64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/60.0.3112.50 Safari/537.36'\n",
    "chrome_options = ChromeOptions()\n",
    "chrome_options.add_argument(f'user-agent={user_agent}')\n",
    "chrome_options.add_argument('--headless')\n",
    "\n",
    "## directory for meta data\n",
    "cwd = os.getcwd()\n",
    "os.chdir('../resource/temp/')\n",
    "csv_location = os.getcwd()\n",
    "os.chdir(cwd)\n",
    "prefs = {\"download.default_directory\": csv_location, \n",
    "         \"download.directory_upgrade\": True, \n",
    "         \"download.prompt_for_download\": False}\n",
    "chrome_options.add_experimental_option('prefs', prefs)\n",
    "\n",
    "## connect to redfin webpage\n",
    "url_redfin = 'https://www.redfin.com/'\n",
    "browser = webdriver.Chrome(options=chrome_options)\n",
    "browser.get(url_redfin)\n",
    "time.sleep(5)\n",
    "\n",
    "## login \n",
    "email = 'john.lukestein@gmail.com'\n",
    "password = 'redfin.0504'\n",
    "login_to_redfin(browser, email, password)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "## cities links\n",
    "city = dict()\n",
    "city['names'], city['links'] = get_cities_links(browser)\n",
    "##\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "browser.quit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('../test.csv', 'r+') as f:\n",
    "    existing_lines = [line for line in csv.reader(f, delimiter=',')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n"
     ]
    }
   ],
   "source": [
    "x = ['SALE TYPE', 'SOLD DATE', 'PROPERTY TYPE', 'ADDRESS', 'CITY', 'STATE OR PROVINCE', 'ZIP OR POSTAL CODE', 'PRICE', 'BEDS', 'BATHS', 'LOCATION', 'SQUARE FEET', 'LOT SIZE', 'YEAR BUILT', 'DAYS ON MARKET', '$/SQUARE FEET', 'HOA/MONTH', 'STATUS', 'NEXT OPEN HOUSE START TIME', 'NEXT OPEN HOUSE END TIME', 'URL (SEE https://www.redfin.com/buy-a-home/comparative-market-analysis FOR INFO ON PRICING)', 'SOURCE', 'MLS#', 'FAVORITE', 'INTERESTED', 'LATITUDE', 'LONGITUDE']\n",
    "if x in existing_lines:\n",
    "    print(True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.rename('../test.csv', '../data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['../data.csv']"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "glob.glob('../*.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.path.exists('../test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['In accordance with local MLS rules, some MLS listings are not included in the download']\n"
     ]
    }
   ],
   "source": [
    "with open('../data.csv', 'r+') as f:\n",
    "    for i, a in enumerate(csv.reader(f, delimiter=',')):\n",
    "        if i == 1:\n",
    "            print(a)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "web_scrapping",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
